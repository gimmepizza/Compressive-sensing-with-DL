{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ddp_beni.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tURyBfB4kgSp"
      },
      "source": [
        "#Compressive Sensing using Deep Learning\n",
        "\n",
        "Due to increaing complexity of devices, the need for more data is constantly increasing, which in turn increases the need for more sensors in a compact region. Although there are state of the art compression models present but most require high computation power to compress. Which is not feasable at a sensor level.\n",
        "This can be overcome through  compressive sensing, where we measure fewer datapoints, and decode back the full data. Mathematically the problem reduces to finding $X  \\in R^m$ given $Y \\in R^N$ , $A\\in R^{m x n}$ and $N\\in R^n$ is gaussian noise: $$Y = AX + N$$ \n",
        "The focus of our problem is the situation when $m > n$ ,because we wish to decompress our measured signal, $Y$, with the added assumption that $X$ is sparse. The goal of compressive sensing is to achieve compression greater than what nyquist thorem states, by exploiting the sparseness of the signal. \\\\\n",
        "Applications of compressive sensing lies in various fields of study ranging from photography to network tomography. Some existing methods to achieve compressive sensing are: \n",
        "\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "#Project timeline\n",
        "July - August:\n",
        "Goal\n",
        "sept oct \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwkPn0qUdZQG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.fftpack import fft,dct\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from scipy.sparse import random\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "from keras import backend as K\n",
        "from sklearn.linear_model import OrthogonalMatchingPursuit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nb_inrqYcBwD"
      },
      "source": [
        "Schematic flow:\n",
        "X' is sparse matrix\n",
        "\n",
        "      X  --Tranform-->   FX  -->  Y = (AFX + noise) --> Neural Network -->  FX'   --Tranform-->  X' --Thresholding-->  X'_thresh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x43ueiHSEnyH"
      },
      "source": [
        "Clarifications: Y is the input to NN X is the output. X and Y are governed by  the equation: Y= AX +B  ,where B is noise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_zQ4ZBOfTNh"
      },
      "source": [
        "# Initializations\n",
        "dimension = 100\n",
        "equations = 50\n",
        "A = np.random.rand(equations,dimension)\n",
        "n = 10000 # no of points to generate\n",
        "eval_n = 5000 #points to eval/validate model on\n",
        "test_n = 5000 #testing\n",
        "mu = 0\n",
        "test_sigma = 0.2 # mean and std dev for gaussian noise for testing noise , usually kept high\n",
        "train_sigma = 0.01\n",
        "min_freq= 0\n",
        "max_freq = 20 #make sure this is not >= dimension/5\n",
        "num_of_waves = 10\n",
        "cardinality = 10\n",
        "multiplier =1\n",
        "# print(A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUvggB-WfmsB"
      },
      "source": [
        "#generating db\n",
        "def generate_db(mu,sigma,A,dimension,equations,n):\n",
        "  x = np.empty((n,dimension), dtype = np.float32)\n",
        "  y = np.empty((n,equations), dtype = np.float32)\n",
        "  for i in range(n):\n",
        "    tempx = np.random.rand(dimension)\n",
        "    noise = np.random.normal(mu, sigma, [equations]) \n",
        "    tempy = np.matmul(A,tempx) + noise\n",
        "    x[i] = tempx\n",
        "    y[i] = tempy\n",
        "  return x,y\n",
        "# This is a non vectorized version for sine wave generation, so slow, use when debugging\n",
        "# def generate_db_sine(mu,sigma,A,dimension,equations,n,min_freq = 0.1,max_freq=20,k=1):\n",
        "#   Fs = dimension\n",
        "#   time = np.arange(Fs)/Fs\n",
        "#   x = np.empty((n,dimension), dtype = np.float32)\n",
        "#   y = np.empty((n,equations), dtype = np.float32)\n",
        "#   for i in range(n):\n",
        "#     f = 13.34935244#np.random.uniform(min_freq,max_freq)\n",
        "#     phi = np.random.uniform(0,2*np.pi)\n",
        "#     tempx= np.sin((2 * np.pi * f * time / Fs)+phi)\n",
        "#     noise = np.random.normal(mu, sigma, [equations]) \n",
        "#     tempy = np.matmul(A,tempx) + noise\n",
        "#     x[i] = tempx\n",
        "#     y[i] = tempy\n",
        "#   return x,y,f\n",
        "\n",
        "def generate_db_sine(mu,sigma,A,dimension,equations,n,\n",
        "                     min_freq = 0.1,max_freq=25):\n",
        "  #m = dimension ; n = equations ; A = CS matrix\n",
        "  Fs = dimension \n",
        "  time = np.arange(Fs).reshape(1,Fs)/Fs\n",
        "  f = np.random.uniform(min_freq,max_freq,(n,1))\n",
        "  phi = np.random.uniform(0,2*np.pi,(n,1))\n",
        "  datx = np.cos(((np.outer(time,f)*2*np.pi).T)).T\n",
        "  noise = np.random.normal(mu, sigma, (equations,n))\n",
        "  daty = np.matmul(A,datx)+noise\n",
        "  return datx.T,daty.T\n",
        "\n",
        "def generate_db_sine_multiple(mu,sigma,A,dimension,\n",
        "                              equations,n,min_freq =\n",
        "                              0.1,max_freq=20,k=1):\n",
        "  x = np.zeros((n,dimension), dtype = np.float32)\n",
        "  y = np.zeros((n,equations), dtype = np.float32)\n",
        "  for i in range(k):\n",
        "    x1,y1 = generate_db_sine(mu,sigma,A,dimension,equations,n,min_freq,max_freq)\n",
        "    x = np.add(x,x1)\n",
        "    y = np.add(y,y1)\n",
        "  return x,y\n",
        "  \n",
        "def generate_db_sparse(mu,sigma,num_of_waves,dimension,equations,n,A,cardinality):\n",
        "  \n",
        "  x = np.zeros((n,dimension), dtype = np.float32)\n",
        "  y = np.zeros((equations,n,dimension+1,1), dtype = np.float32)\n",
        "  y_unmodified = np.zeros((n,equations), dtype = np.float32)\n",
        "  # sums = np.sum(A,axis =1)\n",
        "  # print(len(sums),\"sums \",sums )\n",
        "  # A1 = np.reshape(A,(1,dimension*equations))\n",
        "  # temp = np.ones(n)\n",
        "  # temp = np.reshape(temp,(n,1))\n",
        "  # temp = temp*A1\n",
        "  # print(temp.shape)\n",
        "  y_ret = np.empty([n, dimension+1,equations])\n",
        "  for i in range(n):\n",
        "    x[i] = ((random(1, dimension, density=num_of_waves/dimension).A))\n",
        "    # print(x[i])\n",
        "    temp = (x[i]>0).astype(int)\n",
        "    x[i] = (x[i]*cardinality).astype(int)\n",
        "    # x[i] = np.reshape(x[i],(dimension,1))\n",
        "    # x=(x>0).astype(int);\n",
        "    \n",
        "    noise = np.random.normal(mu, sigma, (equations))\n",
        "    y_temp = np.matmul(A,x[i].T)+noise\n",
        "    # print(y_temp)\n",
        "    # y_temp = np.divide(y_temp,sums)\n",
        "    # print(y_temp)\n",
        "    y_unmodified[i]= y_temp\n",
        "    y_temp = y_temp.reshape((equations,1))\n",
        "    # print(x[i].shape,noise.shape,y_temp.shape) \n",
        "    # print(y_temp)\n",
        "    mesa_t = np.append(y_temp,A,axis =1)\n",
        "    y_ret[i]=(np.transpose(np.array(mesa_t)))\n",
        "    # flattened = np.reshape(mesa_t,(equations*(dimension+1)))\n",
        "    # for j in range(equations):\n",
        "    #   t=flattened[j*(dimension+1):(j+1)*(dimension+1)]\n",
        "    #   y[j][i]= t.reshape((len(t),1))\n",
        "\n",
        "  # y_ret = []\n",
        "  # for j in range(equations):\n",
        "  #   y_ret.append(y[j])#.reshape((y[j].shape[0],1)))\n",
        "    # print(temp)\n",
        "  # print(A)\n",
        "  #--------\n",
        "  # x=(x>0).astype(int);\n",
        "  x= x*multiplier\n",
        "  # x = x-1\n",
        "  # y = np.concatenate((y.T,temp),axis =1)\n",
        "  # print(x,y)\n",
        "  return y_unmodified,x,y_ret;\n",
        "  # To save into csv \n",
        "  # with open('dbx', 'wb') as dbx:\n",
        "  #   np.save(dbx,x)\n",
        "\n",
        "  # with open('dby', 'wb') as dby:\n",
        "  #   np.save(dby,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex9cN-BxjZzh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dd67a16-f2c0-4f61-fbc8-4e5d4d017b41"
      },
      "source": [
        "# x_train,y_train = generate_db_sine_multiple(mu,train_sigma,A,dimension,equations,n,min_freq,max_freq,num_of_waves)\n",
        "y_unmodified,x_train,y_train = generate_db_sparse(mu,train_sigma,num_of_waves,dimension,equations,1,A,cardinality)\n",
        "print(x_train.shape,len(y_train),len(y_train[0]),len(y_train[0][0]),len(y_unmodified),len(y_unmodified[0]))\n",
        "print(x_train)\n",
        "print(y_train.shape)\n",
        "print(y_unmodified.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 100) 1 101 50 1 50\n",
            "[[3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 7. 0. 0. 0.\n",
            "  0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 2. 4. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 5. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 3. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 7. 0. 0. 0.\n",
            "  0. 0. 0. 0.]]\n",
            "(1, 101, 50)\n",
            "(1, 50)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwxRdBpQuLZg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "ee399683-f777-4238-fc2f-a19d3157d373"
      },
      "source": [
        "'''\n",
        "# The model\n",
        "def model_noise(x,y,x_test,y_test):\n",
        "  \n",
        "  \n",
        "  y_in = keras.Input(shape=(equations))\n",
        "  ly = keras.layers.Dense(equations*8, activation='relu')(y_in)# input_shape=[equations+ dimension*equations]),\n",
        "  y_out = keras.layers.Dense(equations*4, activation='relu')(ly)\n",
        "  # modely = keras.Model(inputs=y_in, outputs=y_out, name=\"y_model\")\n",
        "  \n",
        "  A_in = keras.Input(shape=(dimension*equations))\n",
        "  lA = keras.layers.Dense(dimension*equations/2, activation='relu')(A_in)# input_shape=[equations+ dimension*equations]),\n",
        "  A_out = keras.layers.Dense(dimension*equations/100, activation='relu')(lA)# input_shape=[equations+ dimension*equations]),\n",
        "  # modelA = keras.Model(inputs=A_in, outputs=A_out, name=\"A_model\")\n",
        "  # print(modely.output.shape,modelA.output.shape)\n",
        "  combined = tf.keras.layers.concatenate([y_out, A_out])\n",
        "\n",
        "  lc1 = keras.layers.Dense(dimension*8, activation='relu')(combined)\n",
        "  lc2 = keras.layers.Dense(dimension*4, activation='relu')(lc1)\n",
        "    # keras.layers.Dense(dimension, activation='sigmoid') # for sparse 1 0 output\n",
        "  c_out = keras.layers.Dense(dimension, activation='linear')(lc2) # for sparse 1 0 output\n",
        "  modelC = keras.Model(inputs=[y_in,A_in], outputs=c_out, name=\"c_model\")\n",
        "\n",
        "  modelC.compile(loss='mse', optimizer='adam', metrics=['logcosh', 'mse'])\n",
        "  \n",
        "  Aa= np.array(A)\n",
        "  A1 = np.reshape(Aa,(1,dimension*equations))\n",
        "  temp = np.ones(y.shape[0])\n",
        "  temp = np.reshape(temp,(y.shape[0],1))\n",
        "  temp = temp*A1\n",
        "  temp2 = np.ones(y_test.shape[0])\n",
        "  temp2 = np.reshape(temp2,(y_test.shape[0],1))\n",
        "  temp2 = temp2*A1\n",
        "  print(\"hello: \" ,y.shape,temp.shape)\n",
        "  z = [y,temp]\n",
        "  print(len(z),len(z[0]),len(z[0][0]),len(z[1][0]))\n",
        "  history = modelC.fit([y,temp], x,validation_data=([y_test,temp2],x_test), epochs=200,verbose=0)\n",
        "  print(modelC.summary())\n",
        "\n",
        "  #evaluating on trained noise data\n",
        "  # eval_train_noise = model.evaluate(y[-eval_n:],x[-eval_n:],verbose=0)\n",
        "\n",
        "  #evaluating on high noise data\n",
        "  # diff = np.square(high_noise_data[0] - model.predict(high_noise_data[1]))\n",
        "  # mse_high_noise = (np.apply_along_axis(np.sum,1,diff))/(dimension)\n",
        "  \n",
        "  # return np.average(mse_high_noise), eval_train_noise[0],model,history\n",
        "  return modelC,history\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n# The model\\ndef model_noise(x,y,x_test,y_test):\\n  \\n  \\n  y_in = keras.Input(shape=(equations))\\n  ly = keras.layers.Dense(equations*8, activation=\\'relu\\')(y_in)# input_shape=[equations+ dimension*equations]),\\n  y_out = keras.layers.Dense(equations*4, activation=\\'relu\\')(ly)\\n  # modely = keras.Model(inputs=y_in, outputs=y_out, name=\"y_model\")\\n  \\n  A_in = keras.Input(shape=(dimension*equations))\\n  lA = keras.layers.Dense(dimension*equations/2, activation=\\'relu\\')(A_in)# input_shape=[equations+ dimension*equations]),\\n  A_out = keras.layers.Dense(dimension*equations/100, activation=\\'relu\\')(lA)# input_shape=[equations+ dimension*equations]),\\n  # modelA = keras.Model(inputs=A_in, outputs=A_out, name=\"A_model\")\\n  # print(modely.output.shape,modelA.output.shape)\\n  combined = tf.keras.layers.concatenate([y_out, A_out])\\n\\n  lc1 = keras.layers.Dense(dimension*8, activation=\\'relu\\')(combined)\\n  lc2 = keras.layers.Dense(dimension*4, activation=\\'relu\\')(lc1)\\n    # keras.layers.Dense(dimension, activation=\\'sigmoid\\') # for sparse 1 0 output\\n  c_out = keras.layers.Dense(dimension, activation=\\'linear\\')(lc2) # for sparse 1 0 output\\n  modelC = keras.Model(inputs=[y_in,A_in], outputs=c_out, name=\"c_model\")\\n\\n  modelC.compile(loss=\\'mse\\', optimizer=\\'adam\\', metrics=[\\'logcosh\\', \\'mse\\'])\\n  \\n  Aa= np.array(A)\\n  A1 = np.reshape(Aa,(1,dimension*equations))\\n  temp = np.ones(y.shape[0])\\n  temp = np.reshape(temp,(y.shape[0],1))\\n  temp = temp*A1\\n  temp2 = np.ones(y_test.shape[0])\\n  temp2 = np.reshape(temp2,(y_test.shape[0],1))\\n  temp2 = temp2*A1\\n  print(\"hello: \" ,y.shape,temp.shape)\\n  z = [y,temp]\\n  print(len(z),len(z[0]),len(z[0][0]),len(z[1][0]))\\n  history = modelC.fit([y,temp], x,validation_data=([y_test,temp2],x_test), epochs=200,verbose=0)\\n  print(modelC.summary())\\n\\n  #evaluating on trained noise data\\n  # eval_train_noise = model.evaluate(y[-eval_n:],x[-eval_n:],verbose=0)\\n\\n  #evaluating on high noise data\\n  # diff = np.square(high_noise_data[0] - model.predict(high_noise_data[1]))\\n  # mse_high_noise = (np.apply_along_axis(np.sum,1,diff))/(dimension)\\n  \\n  # return np.average(mse_high_noise), eval_train_noise[0],model,history\\n  return modelC,history\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jPq9Ij30UFA"
      },
      "source": [
        "# def custom_mse(y_true, y_pred):\n",
        "#         return K.square(K.mean(K.square(y_pred - y_true)))\n",
        "# The model\n",
        "def model_noise(x,y,x_test,y_test):\n",
        "  # layers = []\n",
        "  # inputs = []\n",
        "  lrelu = lambda x: tf.keras.activations.relu(x, alpha=0.05)\n",
        "  # for i in range(0,equations):\n",
        "  model = keras.models.Sequential()\n",
        "  # input_l  = keras.Input(shape=(dimension+1,equations))  \n",
        "  model.add(layers.LSTM(dimension,input_shape=((dimension+1,equations)) ,activation=\"tanh\", recurrent_activation=\"sigmoid\",use_bias=True,\n",
        "                        return_sequences=True))\n",
        "  model.add(layers.LSTM(dimension, activation=\"tanh\",recurrent_activation=\"sigmoid\",use_bias=True,return_sequences=False))\n",
        "  model.add(layers.Dense(dimension*2, activation=lrelu))\n",
        "\n",
        "  # added_layer = keras.layers.Average()(layers)\n",
        "  # print(len(layers),layers[0].shape)\n",
        "  # print(len(inputs),inputs[0].shape)\n",
        "  print(multiplier, \"in func\")\n",
        "\n",
        "  # model.add(layers.Dense(dimension*8, activation=lrelu))\n",
        "  # lc2 = keras.layers.Dense(dimension*4, activation= lrelu)(lc1)\n",
        "  # lc3 = keras.layers.Dense(dimension*2, activation= lrelu)(lc2)\n",
        "  # model.add(layers.Dense(dimension*2, activation= lrelu))\n",
        "  # keras.layers.Dense(dimension, activation='sigmoid') # for sparse 1 0 output\n",
        "  model.add(layers.Dense(dimension, activation='linear'))# for sparse 1 0 output\n",
        "  \n",
        "  # modelC = keras.Model(inputs = input_l,outputs = c_out, name=\"c_model\")\n",
        "  # opt = keras.optimizers.Adam(learning_rate=0.001,decay = 0.001)\n",
        "  model.compile(loss=\"mse\", optimizer='adam', metrics=['logcosh', 'mse'])\n",
        "  #--------Set up data\n",
        "  print(model.summary())\n",
        "  from keras.utils.vis_utils import plot_model\n",
        "  plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "  es = EarlyStopping(monitor='loss', mode='min', verbose=1,patience = 100, min_delta = 0.001)\n",
        "  \n",
        "  history = model.fit(y, x,validation_data=(y_test,x_test),batch_size = 500, epochs=20,verbose=2)#,callbacks= [es])\n",
        " \n",
        "\n",
        "  #evaluating on trained noise data\n",
        "  # eval_train_noise = model.evaluate(y[-eval_n:],x[-eval_n:],verbose=0)\n",
        "\n",
        "  #evaluating on high noise data\n",
        "  # diff = np.square(high_noise_data[0] - model.predict(high_noise_data[1]))\n",
        "  # mse_high_noise = (np.apply_along_axis(np.sum,1,diff))/(dimension)\n",
        "  \n",
        "  # return np.average(mse_high_noise), eval_train_noise[0],model,history\n",
        "  return model,history\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oE3O4AFUL5RX"
      },
      "source": [
        "# #Plotting\n",
        "# plt.plot(sigmas,high_noise_mses,'b-',label = \"Low noise \")\n",
        "# plt.plot(sigmas,train_noise_mses,'r-',label = \"Training noise \")\n",
        "# plt.ylabel('MSE of Error')\n",
        "# plt.xlabel('Sigma')\n",
        "# plt.legend()\n",
        "# # plt.savefig('0_1_to_1_gaussian_0.05.png')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Ovpwp43vL2"
      },
      "source": [
        "# Train model \n",
        "def model_it(cardinality):\n",
        "  import time\n",
        "  tick1 = time.time()\n",
        "  y_temp,x_train,y_train = generate_db_sparse(mu,train_sigma,num_of_waves,dimension,equations,n,A,cardinality)\n",
        "  # x_test,y_test = generate_db_sine_multiple(mu,test_sigma,A,dimension,equations,eval_n,min_freq,max_freq,num_of_waves)\n",
        "  y_unmodified,x_test,y_test = generate_db_sparse(mu,train_sigma,num_of_waves,dimension,equations,eval_n,A,cardinality)\n",
        "  # miprint(x_train.shape,y_train.shape)\n",
        "  # print(x_t est.shape,y_test.shape)\n",
        "  \n",
        "  print(np.array(y_train).shape)\n",
        "  print(np.array(y_test).shape)\n",
        "  print(x_train.shape)\n",
        "  print(x_test.shape)\n",
        "  print(x_test[1])\n",
        "  model,history = model_noise(x_train,y_train,x_test,y_test)\n",
        "  tock1 = time.time()\n",
        "  print(tock1-tick1)\n",
        "\n",
        "  ## SAVE MODEL\n",
        "  model.save(\"model.h5\")\n",
        "  return model,history, x_test,y_test,y_unmodified\n",
        " \n",
        "# model,history, x_test,y_test = model_it(cardinality)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08cOs1mFah37"
      },
      "source": [
        "## LOAD model\n",
        "# from keras.models import load_model\n",
        "# model = load_model('model.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VswI_pnp-UQB"
      },
      "source": [
        "# Plot loss(mse)\n",
        "\n",
        "# plt.plot(history.history['loss'][100:2000])\n",
        "# plt.plot(history.history['val_loss'][100:2000])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5sckOxZkijh"
      },
      "source": [
        "#Metrics evaluation of model trained\n",
        "#Seeing just one example sine wave\n",
        "# x = np.empty((1,dimension), dtype = np.float32)\n",
        "# y = np.empty((1,equations), dtype = np.float32)\n",
        "# x,y = generate_db_sparse(mu,train_sigma,10 ,dimension,equations,1,A)\n",
        "\n",
        "#Test analysis\n",
        "# test_n = 5000\n",
        "# x = np.empty((test_n,dimension), dtype = np.float32)\n",
        "# y = np.empty((test_n,equations), dtype = np.float32)\n",
        "# _,x,y = generate_db_sparse(mu,train_sigma,10 ,dimension,equations,test_n,A,cardinality)\n",
        "# x1 = model.predict(y)\n",
        "\n",
        "# print(\"mse of example :\",((x1-x[0])**2).mean())\n",
        "# print((x[0]).astype(int),\"\\n\",(np.round(x1[0])).astype(int))\n",
        "# plt.plot(x[0],'r.',(x1[0]),'b')\n",
        "\n",
        "\n",
        "# #complete metric\n",
        "# print(\"Training loss   :\",history.history[\"loss\"][-1])\n",
        "# print(\"Validation loss :\", history.history[\"val_loss\"][-1])\n",
        "\n",
        "# Red is noise free input, Blue is predicted by model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeMCZxPLhYv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b7fc1842-e13f-4863-8fef-cd1ac76023fb"
      },
      "source": [
        "#analysis using x and x1 , to find which all values are correctly classified\n",
        "# x(true)   x1(predicted)\n",
        "# for i in range(test_n):\n",
        "# x = x/4\n",
        "# x1 = np.round(x1/4)\n",
        "\"\"\"\n",
        "x1 = np.multiply((x1>0),x1)\n",
        "z = np.multiply((x==x1).astype(int),x.astype(int))\n",
        "unique_elements_true, counts_elements_true = np.unique(x.astype(int), return_counts=True)\n",
        "unique_elements_predicted, counts_elements_predicted= np.unique(z, return_counts=True)\n",
        "print(\"exact value analysis\")\n",
        "print(unique_elements_true, counts_elements_true)\n",
        "print(unique_elements_predicted, counts_elements_predicted)\n",
        "print(unique_elements_predicted, counts_elements_predicted/counts_elements_true)\n",
        "\n",
        "\n",
        "#sparseness analysis\n",
        "print(\"Sparse value analysis\")\n",
        "s = (x>0).astype(int)\n",
        "s1 = (x1>0).astype(int)\n",
        "tp = np.logical_and((s==s1),(1)).astype(int)\n",
        "# fp = np.logical_and((s==s1),(s==0)).astype(int)\n",
        "sparse_unique_elements_true, sparse_counts_elements_true = np.unique(s.astype(int), return_counts=True)\n",
        "sparse_unique_elements_predicted, sparse_counts_elements_predicted= np.unique(tp, return_counts=True)\n",
        "print(sparse_unique_elements_true, sparse_counts_elements_true)\n",
        "print(sparse_unique_elements_predicted, sparse_counts_elements_predicted/(test_n*dimension))\n",
        "print(sparse_unique_elements_predicted, sparse_counts_elements_predicted/sparse_counts_elements_true)\n",
        "\n",
        "# print((x[1]).astype(int))\n",
        "print()\n",
        "\"\"\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nx1 = np.multiply((x1>0),x1)\\nz = np.multiply((x==x1).astype(int),x.astype(int))\\nunique_elements_true, counts_elements_true = np.unique(x.astype(int), return_counts=True)\\nunique_elements_predicted, counts_elements_predicted= np.unique(z, return_counts=True)\\nprint(\"exact value analysis\")\\nprint(unique_elements_true, counts_elements_true)\\nprint(unique_elements_predicted, counts_elements_predicted)\\nprint(unique_elements_predicted, counts_elements_predicted/counts_elements_true)\\n\\n\\n#sparseness analysis\\nprint(\"Sparse value analysis\")\\ns = (x>0).astype(int)\\ns1 = (x1>0).astype(int)\\ntp = np.logical_and((s==s1),(1)).astype(int)\\n# fp = np.logical_and((s==s1),(s==0)).astype(int)\\nsparse_unique_elements_true, sparse_counts_elements_true = np.unique(s.astype(int), return_counts=True)\\nsparse_unique_elements_predicted, sparse_counts_elements_predicted= np.unique(tp, return_counts=True)\\nprint(sparse_unique_elements_true, sparse_counts_elements_true)\\nprint(sparse_unique_elements_predicted, sparse_counts_elements_predicted/(test_n*dimension))\\nprint(sparse_unique_elements_predicted, sparse_counts_elements_predicted/sparse_counts_elements_true)\\n\\n# print((x[1]).astype(int))\\nprint()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Zpx3DNx4Tul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f62aa37-bfc8-473f-c814-66cc59a82bab"
      },
      "source": [
        "# for i in range(2,11):\n",
        "#   print(\"Cardinality: \",i)\n",
        "#   model,history, x_test,y_test = model_it(i)\n",
        "#   print(\"Training loss   :\",history.history[\"loss\"][-1])\n",
        "#   print(\"Validation loss :\", history.history[\"val_loss\"][-1])\n",
        "#   x1 = model.predict(y_test)\n",
        "#   x1 = np.round(np.multiply((x1>0),x1))  \n",
        "#   s = (x_test>0).astype(int)\n",
        "#   s1 = (x1>0).astype(int)\n",
        "#   tp = np.logical_and((s==s1),(1)).astype(int)\n",
        "#   sparse_unique_elements_true, sparse_counts_elements_true = np.unique(s.astype(int), return_counts=True)\n",
        "#   sparse_unique_elements_predicted, sparse_counts_elements_predicted= np.unique(tp, return_counts=True)\n",
        "#   print(\"Percentage Accuracy: [Wrong,Right]:\" ,100* sparse_counts_elements_predicted/(test_n*dimension))\n",
        "#   print(\"\\n\")\n",
        "# print(model)\n",
        "\n",
        "\"\"\"\n",
        "for i in range(10,11):\n",
        "  print(\"Multiplier: \",i)\n",
        "  multiplier = i\n",
        "  model,history, x_test,y_test = model_it(10)\n",
        "  print(\"Training loss   :\",history.history[\"loss\"][-1])\n",
        "  print(\"Validation loss :\", history.history[\"val_loss\"][-1])\n",
        "  x1 = model.predict(y_test)\n",
        "  x_test = x_test/i\n",
        "  x1 = x1/i\n",
        "  x1 = np.round(x1)\n",
        "  x1 = np.multiply((x1>0),x1)  \n",
        "  s = (x_test>0).astype(int)\n",
        "  s1 = (x1>0).astype(int)\n",
        "  tp = np.logical_and((s==s1),(1)).astype(int)\n",
        "  sparse_unique_elements_true, sparse_counts_elements_true = np.unique(s.astype(int), return_counts=True)\n",
        "  sparse_unique_elements_predicted, sparse_counts_elements_predicted= np.unique(tp, return_counts=True)\n",
        "  print(\"Percentage Accuracy: [Wrong,Right]:\" ,100* sparse_counts_elements_predicted/(test_n*dimension))\n",
        "  print(\"\\n\")\n",
        "\"\"\"\n",
        "#---------------\n",
        "model,history, x_test,y_test,y_unmodified = model_it(10)\n",
        "print(\"Training loss   :\",history.history[\"loss\"][-1])\n",
        "print(\"Validation loss :\", history.history[\"val_loss\"][-1])\n",
        "model_x = model.predict(y_test)\n",
        "model_x = np.round(model_x)\n",
        "model_x = np.multiply((model_x>0),model_x)\n",
        "\n",
        "true_x = (x_test>0).astype(int)\n",
        "model_x = (model_x>0).astype(int)\n",
        "\n",
        "omp = OrthogonalMatchingPursuit(n_nonzero_coefs=num_of_waves)\n",
        "omp.fit(A, y_unmodified[1])\n",
        "omp_x= omp.coef_\n",
        "# omp_x = np.round(omp_x)\n",
        "# omp_x = np.multiply((omp_x>0),omp_x)\n",
        "\n",
        "print(x_test[1],omp_x)\n",
        "print(np.dot(A,x_test[1]),y_unmodified[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 101, 50)\n",
            "(5000, 101, 50)\n",
            "(10000, 100)\n",
            "(5000, 100)\n",
            "[0. 0. 0. 9. 0. 0. 0. 7. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 6. 4. 0. 0. 0. 0. 9. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 8.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0.\n",
            " 0. 0. 0. 9.]\n",
            "1 in func\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 101, 100)          60400     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100)               80400     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 200)               20200     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 100)               20100     \n",
            "=================================================================\n",
            "Total params: 181,100\n",
            "Trainable params: 181,100\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/20\n",
            "20/20 - 35s - loss: 2.7071 - logcosh: 0.4274 - mse: 2.7071 - val_loss: 2.6543 - val_logcosh: 0.4417 - val_mse: 2.6543\n",
            "Epoch 2/20\n",
            "20/20 - 1s - loss: 2.6544 - logcosh: 0.4404 - mse: 2.6544 - val_loss: 2.6504 - val_logcosh: 0.4420 - val_mse: 2.6504\n",
            "Epoch 3/20\n",
            "20/20 - 1s - loss: 2.6531 - logcosh: 0.4410 - mse: 2.6531 - val_loss: 2.6497 - val_logcosh: 0.4400 - val_mse: 2.6497\n",
            "Epoch 4/20\n",
            "20/20 - 1s - loss: 2.6526 - logcosh: 0.4403 - mse: 2.6526 - val_loss: 2.6491 - val_logcosh: 0.4412 - val_mse: 2.6491\n",
            "Epoch 5/20\n",
            "20/20 - 1s - loss: 2.6529 - logcosh: 0.4411 - mse: 2.6529 - val_loss: 2.6494 - val_logcosh: 0.4409 - val_mse: 2.6494\n",
            "Epoch 6/20\n",
            "20/20 - 1s - loss: 2.6529 - logcosh: 0.4404 - mse: 2.6529 - val_loss: 2.6495 - val_logcosh: 0.4392 - val_mse: 2.6495\n",
            "Epoch 7/20\n",
            "20/20 - 1s - loss: 2.6528 - logcosh: 0.4407 - mse: 2.6528 - val_loss: 2.6496 - val_logcosh: 0.4428 - val_mse: 2.6496\n",
            "Epoch 8/20\n",
            "20/20 - 1s - loss: 2.6528 - logcosh: 0.4402 - mse: 2.6528 - val_loss: 2.6494 - val_logcosh: 0.4402 - val_mse: 2.6494\n",
            "Epoch 9/20\n",
            "20/20 - 1s - loss: 2.6527 - logcosh: 0.4406 - mse: 2.6527 - val_loss: 2.6495 - val_logcosh: 0.4411 - val_mse: 2.6495\n",
            "Epoch 10/20\n",
            "20/20 - 1s - loss: 2.6527 - logcosh: 0.4407 - mse: 2.6527 - val_loss: 2.6494 - val_logcosh: 0.4412 - val_mse: 2.6494\n",
            "Epoch 11/20\n",
            "20/20 - 1s - loss: 2.6526 - logcosh: 0.4404 - mse: 2.6526 - val_loss: 2.6493 - val_logcosh: 0.4392 - val_mse: 2.6493\n",
            "Epoch 12/20\n",
            "20/20 - 1s - loss: 2.6526 - logcosh: 0.4408 - mse: 2.6526 - val_loss: 2.6494 - val_logcosh: 0.4385 - val_mse: 2.6494\n",
            "Epoch 13/20\n",
            "20/20 - 1s - loss: 2.6525 - logcosh: 0.4405 - mse: 2.6525 - val_loss: 2.6491 - val_logcosh: 0.4383 - val_mse: 2.6491\n",
            "Epoch 14/20\n",
            "20/20 - 1s - loss: 2.6526 - logcosh: 0.4406 - mse: 2.6526 - val_loss: 2.6491 - val_logcosh: 0.4403 - val_mse: 2.6491\n",
            "Epoch 15/20\n",
            "20/20 - 1s - loss: 2.6525 - logcosh: 0.4406 - mse: 2.6525 - val_loss: 2.6492 - val_logcosh: 0.4384 - val_mse: 2.6492\n",
            "Epoch 16/20\n",
            "20/20 - 1s - loss: 2.6524 - logcosh: 0.4404 - mse: 2.6524 - val_loss: 2.6492 - val_logcosh: 0.4400 - val_mse: 2.6492\n",
            "Epoch 17/20\n",
            "20/20 - 1s - loss: 2.6524 - logcosh: 0.4406 - mse: 2.6524 - val_loss: 2.6492 - val_logcosh: 0.4394 - val_mse: 2.6492\n",
            "Epoch 18/20\n",
            "20/20 - 1s - loss: 2.6524 - logcosh: 0.4404 - mse: 2.6524 - val_loss: 2.6492 - val_logcosh: 0.4386 - val_mse: 2.6492\n",
            "Epoch 19/20\n",
            "20/20 - 1s - loss: 2.6525 - logcosh: 0.4406 - mse: 2.6525 - val_loss: 2.6495 - val_logcosh: 0.4406 - val_mse: 2.6495\n",
            "Epoch 20/20\n",
            "20/20 - 1s - loss: 2.6526 - logcosh: 0.4403 - mse: 2.6526 - val_loss: 2.6492 - val_logcosh: 0.4381 - val_mse: 2.6492\n",
            "57.83564114570618\n",
            "Training loss   : 2.6526362895965576\n",
            "Validation loss : 2.649195432662964\n",
            "[0. 0. 0. 9. 0. 0. 0. 7. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 6. 4. 0. 0. 0. 0. 9. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 8.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 6. 0. 0. 0. 0.\n",
            " 0. 0. 0. 9.] [ 0.          0.          0.          9.39334756  0.          0.\n",
            "  0.          7.14523462  0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          6.76338146  4.11031185  0.\n",
            "  0.          0.          0.          8.8619372   0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          5.83163202  0.         -0.07804441  0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          8.34605588\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          0.          0.          0.          0.          0.\n",
            "  0.          5.85651363  0.          0.          0.          0.\n",
            "  0.          0.          0.          8.55002202]\n",
            "[34.15284784 32.57506029 30.45162566 31.43280504 31.57754564 30.431808\n",
            " 37.23212681 31.40442089 33.81971857 34.40309834 38.92491767 28.87442311\n",
            " 43.07028994 33.87915238 28.27340787 24.48062344 28.1578169  30.37863122\n",
            " 36.92288828 35.14769764 39.91017855 31.88630457 35.87052219 39.85641981\n",
            " 30.54595056 33.19650135 31.26199638 25.82029833 43.455778   19.47759034\n",
            " 35.53613525 29.21425127 41.60654796 35.519024   31.73978926 32.50211942\n",
            " 41.41173794 27.07982564 37.52550375 35.94183195 23.28187744 30.48781721\n",
            " 33.54522367 24.06450631 34.80553788 30.17839097 20.76490934 41.28199701\n",
            " 46.01152771 36.63020273] [34.150433 32.581654 30.454245 31.461517 31.566849 30.423733 37.234184\n",
            " 31.401665 33.824177 34.395504 38.937645 28.86446  43.07877  33.888645\n",
            " 28.264576 24.480173 28.155813 30.37844  36.934334 35.128883 39.90959\n",
            " 31.887842 35.87742  39.85297  30.530823 33.201332 31.272316 25.81648\n",
            " 43.4492   19.482595 35.54043  29.217127 41.628056 35.4985   31.729969\n",
            " 32.498844 41.42535  27.065708 37.516697 35.95505  23.279562 30.489166\n",
            " 33.55879  24.041988 34.819515 30.171928 20.752195 41.27951  46.006485\n",
            " 36.62103 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2dNY6la55bA",
        "outputId": "1eb1e723-a5fe-4e36-96ba-3345a3c6f29c"
      },
      "source": [
        "y_unmodified.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXiwGDARS99a"
      },
      "source": [
        "Cardinality:  2\n",
        "Epoch 00879: early stopping\n",
        "379.96951246261597\n",
        "Training loss   : 0.002135766204446554\n",
        "Validation loss : 0.0038868251722306013\n",
        "Percentage Accuracy: [Wrong,Right]: [9.000e-02 9.991e+01]\n",
        "\n",
        "\n",
        "Cardinality:  3\n",
        "Epoch 01044: early stopping\n",
        "448.4506371021271\n",
        "Training loss   : 0.006050974130630493\n",
        "Validation loss : 0.013447360135614872\n",
        "Percentage Accuracy: [Wrong,Right]: [ 0.5308 99.4692]\n",
        "\n",
        "\n",
        "Cardinality:  4\n",
        "512.6081898212433\n",
        "Training loss   : 0.011856448836624622\n",
        "Validation loss : 0.028034768998622894\n",
        "Percentage Accuracy: [Wrong,Right]: [ 1.201 98.799]\n",
        "\n",
        "\n",
        "Cardinality:  5\n",
        "513.373165845871\n",
        "Training loss   : 0.019076654687523842\n",
        "Validation loss : 0.049769770354032516\n",
        "Percentage Accuracy: [Wrong,Right]: [ 2.0802 97.9198]\n",
        "\n",
        "\n",
        "Cardinality:  6\n",
        "512.4558897018433\n",
        "Training loss   : 0.029436489567160606\n",
        "Validation loss : 0.07413434982299805\n",
        "Percentage Accuracy: [Wrong,Right]: [ 3. 97.]\n",
        "\n",
        "\n",
        "Cardinality:  7\n",
        "512.4523162841797\n",
        "Training loss   : 0.03945969417691231\n",
        "Validation loss : 0.10321462154388428\n",
        "Percentage Accuracy: [Wrong,Right]: [ 4.1094 95.8906]\n",
        "\n",
        "\n",
        "Cardinality:  8\n",
        "513.3301746845245\n",
        "Training loss   : 0.05366307497024536\n",
        "Validation loss : 0.14584973454475403\n",
        "Percentage Accuracy: [Wrong,Right]: [ 5.403 94.597]\n",
        "\n",
        "\n",
        "Cardinality:  9\n",
        "512.0672745704651\n",
        "Training loss   : 0.07128644734621048\n",
        "Validation loss : 0.17760775983333588\n",
        "Percentage Accuracy: [Wrong,Right]: [ 6.576 93.424]\n",
        "\n",
        "\n",
        "Cardinality:  10\n",
        "513.6596004962921\n",
        "Training loss   : 0.08878307789564133\n",
        "Validation loss : 0.2388237863779068\n",
        "Percentage Accuracy: [Wrong,Right]: [ 8.5418 91.4582]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qRJwlvURYqi"
      },
      "source": [
        "1 Hidden layer neural network with 4*dimension number of nodes.\n",
        "\n",
        "|Waves| Dimensions   |      Equations      |  train sigma | test sigma |train loss(mse) | test loss | loss on sine wave | Visual obs|\n",
        "|-----:|----------|:-------------:|------:|-------:| -------:|------------:|------------:|-------:|\n",
        "|1| 100 |  100| 0.01 |0.2|0.00096|0.00069|0.01327 |Acceptable\n",
        "|2| 100 |  100| 0.01 |0.2|0.00912|0.01479|0.04617 |Acceptable\n",
        "|3| 100 |  100| 0.01 |0.2|0.01499|0.01059|0.09541 |Single sine results are wavier but acceptable\n",
        "|4| 100 |  100| 0.01 |0.2|0.02960|0.01541|0.07621 |similar to 3\n",
        "|5| 100 |  100| 0.01 |0.2|0.04723|0.02506|0.23794 |similar to 3\n",
        "|6| 100 |  100| 0.01 |0.2|0.05250|0.04264|0.18312 |similar to 3 + bad predictions for 1-2 waves\n",
        "|7| 100 |  100| 0.01 |0.2|0.05741|0.03608|0.21407 |similar to 6 \n",
        "|8| 100 |  100| 0.01 |0.2|0.05123|0.06004|0.22249 |similar to 6 \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDL7QFAExYpZ"
      },
      "source": [
        "2 Hidden layer neural network with 4\\*dimension number of nodes in first and 2\\*dimension in second layer.\n",
        "\n",
        "|Waves| Dimensions   |      Equations      |  train sigma | test sigma |train loss(mse) | test loss | loss on sine wave | Visual obs|\n",
        "|-----:|----------|:-------------:|------:|-------:| -------:|------------:|------------:|-------:|\n",
        "|1| 100 |  100| 0.01 |0.2|0.00049|0.00085|0.00086 |Acceptable\n",
        "|2| 100 |  100| 0.01 |0.2|0.01416|0.00934|0.00768 |1 layer was better ,Acceptable\n",
        "|3| 100 |  100| 0.01 |0.2|0.01610|0.02042|0.04245 |1 layer model was better but single sine is better here\n",
        "|4| 100 |  100| 0.01 |0.2|0.02194|0.02873|0.10675 |similar to 3\n",
        "|5| 100 |  100| 0.01 |0.2|0.03140|0.02925|0.10590 |acceptable , less similar to 3\n",
        "|6| 100 |  100| 0.01 |0.2|0.03668|0.04846|0.08422 |similar to 3 + bad predictions for 1-2 waves\n",
        "|7| 100 |  100| 0.01 |0.2|0.03654|0.05338|0.10207 |similar to 6 \n",
        "|8| 100 |  100| 0.01 |0.2|0.05968|0.07704|0.23905 |similar to 6 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQ9Bfqev6EHU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "322aa885-3f39-46fe-9fe6-6867dd66dd84"
      },
      "source": [
        "train_loss1 = [0.00096,0.00912,0.01499,0.02960,0.04723,0.05250,0.05741,0.05123]\n",
        "test_loss1 = [0.00069,0.01479,0.01059,0.01541,0.02506,0.04264,0.03608,0.06004]\n",
        "train_loss2 = [0.00049,0.01416,0.01610,0.02194,0.03140,0.03668,0.03654,0.05968]\n",
        "test_loss2 = [0.00085,0.000934,0.02042,0.02873,0.02925,0.04846,0.05338,0.07704]\n",
        "sine_loss1=[0.01327,0.04617,0.09541,0.07621,0.023794,0.18312,0.21407,0.22249]\n",
        "sine_loss2 = [0.00086,0.00768,0.04245,0.10675,0.10590,0.08422,0.10207,0.23905]\n",
        "numb_of_waves = np.arange(1,9)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(numb_of_waves,train_loss1,'r-',label= \"train loss 1\")\n",
        "# plt.plot(numb_of_waves,sine_loss1,'r.-',label =\"sine loss 1\")\n",
        "plt.plot(numb_of_waves,train_loss2,'b-',label = \"train loss 2\")\n",
        "plt.plot(numb_of_waves,test_loss1,'r--',label= \"test loss 1\")\n",
        "plt.plot(numb_of_waves,test_loss2,'b--',label = \"test loss 2\")\n",
        "# plt.plot(numb_of_waves,sine_loss2,'b.-',label = \"sine loss 2\")\n",
        "plt.legend()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fabc03ea890>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BljrXgBxmd3G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "69f6a668-012d-4216-d8f4-815c618ccbbc"
      },
      "source": [
        "# Random Codes\n",
        "'''\n",
        "\n",
        "print(x)\n",
        "with open('dbx', 'rb') as f:\n",
        "  meh = np.load(f,allow_pickle=True) \n",
        "print(np.shape(x))\n",
        "print(np.shape(np.transpose(y[80])))\n",
        "print(x)\n",
        "print(y[80])\n",
        "print((y[80].reshape(3)))\n",
        "a =[[1.0421941],[0.8363143], [0.7082898]]\n",
        "print(((avg_error_norm)**2)/(dimension),avg_mse)\n",
        "\n",
        "'''\n",
        "\n",
        "# temp = [[-4, -3, -2],\n",
        "#        [-1,  0,  1],\n",
        "#        [ 2,  3,  4]]\n",
        "\n",
        "# temp2 = list(filter(lambda x: print(np.sum(x),\"\\n\") ,temp))\n",
        "# np.sum(temp2)\n",
        "# print(np.sum(temp[0]))\n",
        "# print(np.square(temp).mean())\n",
        "# x,_ = generate_db_sine_multiple(mu,test_sigma,A,dimension,equations,1,min_freq,max_freq,1)\n",
        "# print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n\\nprint(x)\\nwith open('dbx', 'rb') as f:\\n  meh = np.load(f,allow_pickle=True) \\nprint(np.shape(x))\\nprint(np.shape(np.transpose(y[80])))\\nprint(x)\\nprint(y[80])\\nprint((y[80].reshape(3)))\\na =[[1.0421941],[0.8363143], [0.7082898]]\\nprint(((avg_error_norm)**2)/(dimension),avg_mse)\\n\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfmGMM-sxh2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85a0cbbd-bdb1-42c9-fade-6992212b3e1c"
      },
      "source": [
        "# #trying inverse using A Recurrent Neural Network for Real-Time Matrix Inversion* -Jun Wang\n",
        "import numpy as np\n",
        "# row = 4;col =5\n",
        "# A = np.random.rand(row,row)\n",
        "# A1 = np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12]])\n",
        "# # dv = np.zeros((row,col), dtype=int)\n",
        "# v = np.zeros((row,row), dtype=float)\n",
        "# ya = np.array([13,14,15],[16,17,18])\n",
        "# ya= ya.reshape(3,1)\n",
        "# print(A1,ya)\n",
        "# A1 = np.append(A1,ya,axis=1)\n",
        "# print(A1.reshape(1,15))\n",
        "be = [1,2,3]\n",
        "ce = [3,4,5]\n",
        "de = [be,ce,be,be]\n",
        "print(len(be), len(de),len(de[0]))\n",
        "abc = np.random.rand(4,3)\n",
        "defg = [abc,abc]\n",
        "# defg = [defg,defg]\n",
        "print(len(defg),len(defg[0]),len(defg[0][0]))\n",
        "print(defg)\n",
        "# print(y.reshape(3,1))\n",
        "\n",
        "# eps = 1e-6\n",
        "# n =10000\n",
        "# delta = 1e4\n",
        "# AT = delta*A.T\n",
        "# # temp = -delta*np.matmul(A.T,A)\n",
        "# A_inv = np.linalg.inv(A)\n",
        "# I= np.eye(row, dtype=float)\n",
        "# while n:\n",
        "#   v = v- np.matmul(AT,np.arctan(np.matmul(A,v)-I ))\n",
        "#   # print(np.linalg.norm(A_inv-v),\"\\n\")\n",
        "#   n-=1\n",
        "# print(A,\"\\n\\n\",I  ,\"\\n\\n\",v,\"\\n\\n\",A_inv)\n",
        "# S = random(1, 10, density=4/10)\n",
        "# print(1*(S.A[0]>0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 4 3\n",
            "2 4 3\n",
            "[array([[0.17958206, 0.15919323, 0.67269042],\n",
            "       [0.05231537, 0.60911247, 0.04843116],\n",
            "       [0.48262107, 0.68885384, 0.82392098],\n",
            "       [0.49670995, 0.19739309, 0.16888465]]), array([[0.17958206, 0.15919323, 0.67269042],\n",
            "       [0.05231537, 0.60911247, 0.04843116],\n",
            "       [0.48262107, 0.68885384, 0.82392098],\n",
            "       [0.49670995, 0.19739309, 0.16888465]])]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}